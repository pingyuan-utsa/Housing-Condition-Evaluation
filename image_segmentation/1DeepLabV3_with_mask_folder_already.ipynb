{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f62835ad-b3c3-45f1-bb11-75b71dd30513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e580b96-8174-4c77-b6f5-ae1ede335313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for image + mask pairs\n",
    "class MaskedSegDataset(Dataset):\n",
    "    def __init__(self, root, img_folder=\"images\", mask_folder=\"binary_mask\",\n",
    "                 transform=None, mask_transform=None):\n",
    "\n",
    "        self.img_dir = os.path.join(root, img_folder)\n",
    "        self.mask_dir = os.path.join(root, mask_folder)\n",
    "        self.transform = transform\n",
    "        self.mask_transform = mask_transform\n",
    "\n",
    "        # build full paths\n",
    "        self.img_paths = sorted([\n",
    "            os.path.join(self.img_dir, f)\n",
    "            for f in os.listdir(self.img_dir)\n",
    "            if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "        ])\n",
    "\n",
    "        self.mask_paths = sorted([\n",
    "            os.path.join(self.mask_dir, f)\n",
    "            for f in os.listdir(self.mask_dir)\n",
    "            if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "        ])\n",
    "\n",
    "        print(f\"Found {len(self.img_paths)} images.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # read images and mask\n",
    "        img_path = self.img_paths[idx]\n",
    "        mask_path = self.mask_paths[idx]\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path)\n",
    "\n",
    "        # Image enhancement\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # 3.mask resize\n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)\n",
    "\n",
    "        # mask clean , make sure all values are between 0-9\n",
    "        mask_np = np.array(mask)\n",
    "\n",
    "        # invalid pixels -> 255 ignore_index\n",
    "        mask_np[mask_np > 9] = 255\n",
    "\n",
    "        # Convert back to PIL image\n",
    "        mask = Image.fromarray(mask_np.astype(np.uint8))\n",
    "\n",
    "        # 5. convert into tensor\n",
    "        mask = torch.from_numpy(np.array(mask)).long()\n",
    "\n",
    "        return img, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93acf7a4-7371-4754-8cda-c0171e77df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Script\n",
    "def main():\n",
    "\n",
    "    #path\n",
    "    dataset_path = r\"C:\\Users\\dht233\\OneDrive - University of Texas at San Antonio\\NSF\\Housing condition\\image segmatation\\dataset\\translated_data\"\n",
    "\n",
    "    #  HYPERPARAMS \n",
    "    IMG_SIZE = 512\n",
    "    BATCH_SIZE = 2\n",
    "    NUM_EPOCHS = 50\n",
    "    LR = 1e-4\n",
    "    NUM_CLASSES = 10  # 0–9\n",
    "\n",
    "    # DEVICE \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    # ---------- TRANSFORMS ----------\n",
    "    img_transform = T.Compose([\n",
    "        T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.RandomRotation(10),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    mask_transform = T.Compose([\n",
    "        T.Resize((IMG_SIZE, IMG_SIZE), interpolation=Image.NEAREST)\n",
    "    ])\n",
    "\n",
    "    #  DATASET \n",
    "    train_dataset = MaskedSegDataset(\n",
    "        dataset_path,\n",
    "        img_folder=\"images\",\n",
    "        mask_folder=\"binary_mask\",\n",
    "        transform=img_transform,\n",
    "        mask_transform=mask_transform\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    # MODEL\n",
    "    model = torchvision.models.segmentation.deeplabv3_resnet50(\n",
    "        weights=None, num_classes=NUM_CLASSES\n",
    "    ).to(device)\n",
    "\n",
    "    #LOSS + OPT \n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=0)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    # TRAIN \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "\n",
    "        for images, masks in pbar:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)[\"out\"]\n",
    "\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            pbar.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "        epoch_loss = running_loss / len(train_dataset)\n",
    "        print(f\"Epoch {epoch+1} Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), \"seg_model.pth\")\n",
    "    print(\"Model saved as seg_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c5be01e-10e4-4b46-9cc2-64782a9d0e38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Found 642 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 321/321 [02:50<00:00,  1.88it/s, loss=0.626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 1.1286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 321/321 [02:53<00:00,  1.85it/s, loss=0.635]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.8912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 321/321 [02:51<00:00,  1.88it/s, loss=0.876]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.8538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 321/321 [02:52<00:00,  1.87it/s, loss=0.748]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.8304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████| 321/321 [02:51<00:00,  1.87it/s, loss=1.19] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 0.7960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████| 321/321 [02:51<00:00,  1.88it/s, loss=0.691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 0.7799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████| 321/321 [02:52<00:00,  1.86it/s, loss=0.818]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss: 0.7699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████| 321/321 [02:49<00:00,  1.90it/s, loss=0.727]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss: 0.7582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|██████████| 321/321 [02:49<00:00,  1.89it/s, loss=0.573]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss: 0.7409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|██████████| 321/321 [02:50<00:00,  1.89it/s, loss=0.757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Loss: 0.7230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|██████████| 321/321 [02:50<00:00,  1.88it/s, loss=0.527]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Loss: 0.7011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|██████████| 321/321 [02:49<00:00,  1.89it/s, loss=0.603]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Loss: 0.6953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: 100%|██████████| 321/321 [02:50<00:00,  1.88it/s, loss=0.587]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Loss: 0.6730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: 100%|██████████| 321/321 [02:48<00:00,  1.90it/s, loss=0.652]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Loss: 0.6596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: 100%|██████████| 321/321 [02:49<00:00,  1.89it/s, loss=0.767]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Loss: 0.6441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: 100%|██████████| 321/321 [02:50<00:00,  1.89it/s, loss=0.665]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Loss: 0.6284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: 100%|██████████| 321/321 [02:50<00:00,  1.88it/s, loss=0.519]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Loss: 0.6066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: 100%|██████████| 321/321 [02:51<00:00,  1.87it/s, loss=0.422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Loss: 0.5959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: 100%|██████████| 321/321 [02:51<00:00,  1.87it/s, loss=0.438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Loss: 0.5820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: 100%|██████████| 321/321 [02:51<00:00,  1.87it/s, loss=0.963]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Loss: 0.5675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: 100%|██████████| 321/321 [02:51<00:00,  1.87it/s, loss=0.528]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Loss: 0.5598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: 100%|██████████| 321/321 [02:51<00:00,  1.87it/s, loss=0.559]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Loss: 0.5433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: 100%|██████████| 321/321 [02:49<00:00,  1.89it/s, loss=0.503]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Loss: 0.5330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: 100%|██████████| 321/321 [02:50<00:00,  1.88it/s, loss=0.5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Loss: 0.5086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50: 100%|██████████| 321/321 [02:50<00:00,  1.88it/s, loss=0.507]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Loss: 0.4890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50: 100%|██████████| 321/321 [02:49<00:00,  1.89it/s, loss=0.425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Loss: 0.4874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50: 100%|██████████| 321/321 [02:48<00:00,  1.91it/s, loss=0.332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Loss: 0.4705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50: 100%|██████████| 321/321 [02:49<00:00,  1.89it/s, loss=0.539]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Loss: 0.4576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50: 100%|██████████| 321/321 [02:49<00:00,  1.89it/s, loss=0.39] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Loss: 0.4531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50: 100%|██████████| 321/321 [02:49<00:00,  1.90it/s, loss=0.485]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Loss: 0.4416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: 100%|██████████| 321/321 [02:49<00:00,  1.89it/s, loss=0.287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Loss: 0.4183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50: 100%|██████████| 321/321 [02:49<00:00,  1.90it/s, loss=0.33] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Loss: 0.4097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50: 100%|██████████| 321/321 [02:49<00:00,  1.90it/s, loss=0.508]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Loss: 0.4076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50: 100%|██████████| 321/321 [02:49<00:00,  1.89it/s, loss=0.476]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Loss: 0.4012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50: 100%|██████████| 321/321 [02:49<00:00,  1.89it/s, loss=0.401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Loss: 0.3835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50: 100%|██████████| 321/321 [02:49<00:00,  1.89it/s, loss=0.399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Loss: 0.3873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50: 100%|██████████| 321/321 [02:48<00:00,  1.90it/s, loss=0.389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Loss: 0.3698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50: 100%|██████████| 321/321 [02:49<00:00,  1.90it/s, loss=0.256]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Loss: 0.3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50: 100%|██████████| 321/321 [02:50<00:00,  1.89it/s, loss=0.258]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Loss: 0.3528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50: 100%|██████████| 321/321 [02:48<00:00,  1.90it/s, loss=0.211]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Loss: 0.3454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50: 100%|██████████| 321/321 [02:48<00:00,  1.91it/s, loss=0.246]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Loss: 0.3451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50: 100%|██████████| 321/321 [02:49<00:00,  1.90it/s, loss=0.407]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Loss: 0.3341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50: 100%|██████████| 321/321 [02:50<00:00,  1.89it/s, loss=0.211]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Loss: 0.3327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50: 100%|██████████| 321/321 [02:49<00:00,  1.90it/s, loss=0.528]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Loss: 0.3338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50: 100%|██████████| 321/321 [02:49<00:00,  1.89it/s, loss=0.261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Loss: 0.3203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50: 100%|██████████| 321/321 [02:49<00:00,  1.89it/s, loss=0.189]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Loss: 0.3083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50: 100%|██████████| 321/321 [02:50<00:00,  1.88it/s, loss=0.327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Loss: 0.3088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50: 100%|██████████| 321/321 [02:49<00:00,  1.89it/s, loss=0.422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Loss: 0.3084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50: 100%|██████████| 321/321 [02:52<00:00,  1.86it/s, loss=0.324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Loss: 0.2972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50: 100%|██████████| 321/321 [02:51<00:00,  1.87it/s, loss=0.232]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Loss: 0.2884\n",
      "Model saved as seg_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4693b883-6127-4215-a726-0a2c938aed23",
   "metadata": {},
   "source": [
    "###Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d07be453-97e8-4d91-8a8e-925a9d197759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "\n",
    "# Helper functions for forcibly releasing memory\n",
    "def force_clean_memory():\n",
    "    \"\"\"clean memory\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# PARAMETERS \n",
    "device = \"cpu\"\n",
    "MODEL_PATH = \"seg_model.pth\"\n",
    "IMG_SIZE = 256\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "TEST_FOLDER = r\"C:\\Users\\dht233\\OneDrive - University of Texas at San Antonio\\NSF\\Housing condition\\image segmatation\\myima\"\n",
    "\n",
    "# Color map\n",
    "colors = {\n",
    "    0: [0, 0, 0], 1: [70, 70, 70], 2: [250, 170, 30],\n",
    "    3: [70, 130, 180], 4: [0, 60, 100], 5: [153, 153, 153],\n",
    "    6: [107, 142, 35], 7: [255, 0, 0], 8: [0, 0, 142], 9: [220, 220, 0],\n",
    "}\n",
    "\n",
    "def colorize_mask(mask):\n",
    "    h, w = mask.shape\n",
    "    color_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    for cls, color in colors.items():\n",
    "        color_mask[mask == cls] = color\n",
    "    return color_mask\n",
    "\n",
    "def predict_single_image(model, img_path, transform):\n",
    "    \"\"\"cope with single images for clean memory\"\"\"\n",
    "    # load image\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    original_size = img.size\n",
    "    \n",
    "    # Reduce to a reasonable size\n",
    "    if max(img.size) > 512:\n",
    "        img.thumbnail((512, 512), Image.LANCZOS)\n",
    "    \n",
    "    # Resize\n",
    "    img_resized = img.resize((IMG_SIZE, IMG_SIZE), Image.LANCZOS)\n",
    "    \n",
    "    # Transform\n",
    "    x = transform(img_resized).unsqueeze(0)\n",
    "    \n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        out = model(x)[\"out\"]\n",
    "        pred = torch.argmax(out.squeeze(), dim=0).cpu().numpy()\n",
    "    \n",
    "    # Clean up torch variables immediately\n",
    "    del out, x\n",
    "    \n",
    "    return img_resized, pred\n",
    "\n",
    "def process_and_save(img_path, model, transform, output_folder, index, total):\n",
    "    \"\"\"cope with and save single image\"\"\"\n",
    "    base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    print(f\"\\nProcessing {index}/{total}: {base_name}\")\n",
    "    \n",
    "    try:\n",
    "        # predict\n",
    "        img_resized, pred = predict_single_image(model, img_path, transform)\n",
    "        \n",
    "        # generate colorful mask\n",
    "        colored_mask = colorize_mask(pred)\n",
    "        \n",
    "        # save mask\n",
    "        mask_path = os.path.join(output_folder, f\"{base_name}_mask.png\")\n",
    "        mask_img = Image.fromarray(colored_mask)\n",
    "        mask_img.save(mask_path, optimize=True)\n",
    "        print(f\"  ✓ Saved mask\")\n",
    "        \n",
    "        # Save the prediction array\n",
    "        pred_path = os.path.join(output_folder, f\"{base_name}_pred.npy\")\n",
    "        np.save(pred_path, pred)\n",
    "        print(f\"  ✓ Saved prediction array\")\n",
    "        \n",
    "        # Clean up all variables immediately\n",
    "        del img_resized, pred, colored_mask, mask_img\n",
    "        force_clean_memory()\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ ERROR: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        # Even if an error occurs, the memory should be cleared.\n",
    "        force_clean_memory()\n",
    "        return False\n",
    "\n",
    "def run_inference():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Starting inference...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Get image list\n",
    "    imgs = [\n",
    "        os.path.join(TEST_FOLDER, f)\n",
    "        for f in os.listdir(TEST_FOLDER)\n",
    "        if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nFound {len(imgs)} images in folder\")\n",
    "    \n",
    "    if len(imgs) == 0:\n",
    "        print(\"No images found!\")\n",
    "        return\n",
    "    \n",
    "    # Create output folder\n",
    "    output_folder = os.path.join(TEST_FOLDER, \"predictions\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    print(f\"Output folder: {output_folder}\")\n",
    "    \n",
    "    # Load model\n",
    "    print(\"\\nLoading model...\")\n",
    "    model = torchvision.models.segmentation.deeplabv3_resnet50(\n",
    "        weights=None, num_classes=NUM_CLASSES\n",
    "    )\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=device, weights_only=True))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(\"✓ Model loaded\")\n",
    "    \n",
    "    # Transform\n",
    "    transform = T.Compose([\n",
    "        T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    # Process each image\n",
    "    success_count = 0\n",
    "    for i, img_path in enumerate(imgs, 1):\n",
    "        if process_and_save(img_path, model, transform, output_folder, i, len(imgs)):\n",
    "            success_count += 1\n",
    "        \n",
    "        # Force cleanup after processing each image.\n",
    "        force_clean_memory()\n",
    "        \n",
    "        # Optional: Limit the number of processes for testing.\n",
    "        # if i >= 1:  # Process only the first one\n",
    "        #     print(\"\\nStopping after first image for testing\")\n",
    "        #     break\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"✓ Processing complete!\")\n",
    "    print(f\"  Successfully processed: {success_count}/{len(imgs)}\")\n",
    "    print(f\"  Output folder: {output_folder}\")\n",
    "    print(\"=\" * 60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d187ada-3395-434f-a00e-40258866e660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Starting inference...\n",
      "============================================================\n",
      "\n",
      "Found 3 images in folder\n",
      "Output folder: C:\\Users\\dht233\\OneDrive - University of Texas at San Antonio\\NSF\\Housing condition\\image segmatation\\myima\\predictions\n",
      "\n",
      "Loading model...\n",
      "✓ Model loaded\n",
      "\n",
      "Processing 1/3: frontview_pic_20250627093308 (1)\n",
      "  ✓ Saved mask\n",
      "  ✓ Saved prediction array\n",
      "\n",
      "Processing 2/3: windows_image_20250627094307\n",
      "  ✓ Saved mask\n",
      "  ✓ Saved prediction array\n",
      "\n",
      "Processing 3/3: windows_image_20250703114731\n",
      "  ✓ Saved mask\n",
      "  ✓ Saved prediction array\n",
      "\n",
      "============================================================\n",
      "✓ Processing complete!\n",
      "  Successfully processed: 3/3\n",
      "  Output folder: C:\\Users\\dht233\\OneDrive - University of Texas at San Antonio\\NSF\\Housing condition\\image segmatation\\myima\\predictions\n",
      "============================================================\n",
      "\n",
      "Memory cleaned\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        run_inference()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nInterrupted by user\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n\\nFATAL ERROR: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        # make sure to clean up finally\n",
    "        force_clean_memory()\n",
    "        print(\"\\nMemory cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac121f74-2a16-438a-8d0c-733457995ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
